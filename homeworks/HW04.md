# SQL - HW04
## Amir ElTabakh
## March 5, 2022

1. Exercise

For each column in the database run the distinct command and record in a table how many distinct records are there. Your output should look like the one below.

|column_name|distinct_records  |
|--|--|
|vendorID  |3  |
|tpep_pickup_datetime  |?  |


...
While I will accept the solution with 17 `SELECT` statements I would encourage you to 
try and achieve this with as few `SELECT` statements as possible. Can you get the distinct count for all 17 columns from a single `SELECT`?

What can you deduce from the row count obtained from hw03 and the distinct record counts obtained in this exercise?

1. Answer

```
select 
count (distinct "VendorID") as VendorID,
count (distinct "tpep_pickup_datetime") as tpep_pickup_datetime,
count (distinct "tpep_dropoff_datetime") as tpep_dropoff_datetime,
count (distinct "passenger_count") as passenger_count,
count (distinct "trip_distance") as trip_distance,
count (distinct "RatecodeID") as RatecodeID,
count (distinct "store_and_fwd_flag") as store_and_fwd_flag,
count (distinct "PULocationID") as PULocationID,
count (distinct "DOLocationID") as DOLocationID,
count (distinct "payment_type") as payment_type,
count (distinct "fare_amount") as fare_amount,
count (distinct "extra") as extra,
count (distinct "mta_tax") as mta_tax,
count (distinct "tip_amount") as tip_amount,
count (distinct "improvement_surcharge") as improvement_surcharge,
count (distinct "total_amount") as total_amount
from taxi_data;
```

|column_name|distinct_records  |
|--|--|
|VendorID  |3  |
|tpep_pickup_datetime  |27,427,744  |
|tpep_dropoff_datetime  |27,456,625  |
|passenger_count  |12  |
|trip_distance  |7,181  |
|RatecodeID  |7  |
|store_and_fwd_flag  |2  |
|PULocationID  |264  |
|DOLocationID  |264  |
|payment_type  |5  |
|fare_amount  |9,839  |
|extra  |45  |
|mta_tax  |65  |
|tip_amount  |6,483  |
|tolls_amount  |3,100  |
|improvement_surcharge  |12  |
|total_amount  |22,606  |

2. Exercise

A subquery allows you to use the output from a previous query as input for another query. Here is one way of constructing a subquery:

```
select count(*) as distinct_observation_count from (select distinct "vendorID", "extra" from "qcmath290"."public"."2018_Yellow_Taxi_Trip_Data") as sub_query;
```

The code I entered can be found in the corresponding SQL script.
The return was `102,804,099`.

The complete query returns the count of a distinct combination of vendorID and extra values in the `2018_Yellow_Taxi_Trip_Data` relation. It achieves this in two steps

 1. select the distinct combination of tuples of the vendorID and extra attributes
 2. count the results from step 1

Build a sub-query that will give you the distinct record count across all 17 columns in the 
`2018_Yellow_Taxi_Trip_Data` relation.

At this point, we know three crucial facts about our dataset:

 1. row count
 2. distinct count of observations in each column (aka cardinality of each column)
 3. total number of unique observations in the dataset

What can you deduce from these 3 key facts? 
Is there any single column in the dataset that could serve as the primary key?
Is there any combination of columns that can serve as the primary key?

2. Answer

To reiterate, we know the row count, we have the count of distinct values per column, and we have the total number of unique observations in the dataset. We can deduce from our findings alone that no single column is suitable to be a primary key. If there were a single column that had the same count of distinct values as there are number of rows, then that column would be a suitable primary key. But there isn't. If the number of unique observations/rows is equal to the number of rows in the dataset then there is at least one column that would be a suitable primary key. But there isn't. We don't have enough information to confirm if there is a combination of columns that can serve as a primary key. However, we can create a composite key.

A composite key is a column made by the combination of two or more columns in a table/entity that can be used to uniquely identify each row in the table when the columns combined uniqueness of a row is guarenteed. It can also be understood as a primary key made by the combination of two or more columns to uniquely identify every row in a table/entity.

3. Exercise

Use the `WHERE` clause introduced in the last class to find the answer to these questions. As a reminder, the most basic form of the where clause can be written like this:

`select * from students where f_name = 'Ronald'`

This query will return every record (tuple) from the students table (relation) where comparing the value found in f_name column with the string 'Ronald' evaluates to true.

The code corresponding to each sub question can be found in the corresponding SQL script.

 - How many rows have a "passenger_count" equal to 5.\
`5,040,905`
 - How many distinct trips have a "passenger_count" greater than 3?\
`8`
 - How many rows have a tpep_pickup_datetime between '2018-04-01 00:00:00' and '2018-05-01 00:00:00'?\
`9,305,362`
 - How many distinct trips occurred in June where the tip_amount was greater than equal to $5.00?\
 `3,105`
 - How many distinct trips occurred in May where the passenger_count was greater than three and tip_amount was between $2.00 and $5.00?\
`290`
 - What is the sum of tip_amount in the `2018_Yellow_Taxi_Trip_Data` dataset? (Hint: use the SUM() function to find the answer)\
`210,156,392.48` 

Can you assume that the answer to your previous question is equivalent to the question of "How much tip did taxi drivers collected in total in 2018?" Explain your answer.

A taxi driver may have recieved a tip in cash, which may have went unreported. So the true sum of tips for taxi drivers may exceed the calculated total.

Please complete exercises 1-3 before you proceed to exercise 4.

4. Exercise

Take note of the base and the database folder's size associated with the database where `2018_Yellow_Taxi_Trip_Data` is located.

|folder_name  | size |
|--|--|
|base  |  |
|databseid  |  |

Delete all records from the `2018_Yellow_Taxi_Trip_Data` where vendorID equals 2.

Record the size of the base folder and the size of the database folder after the delete is completed.

Check if the records got deleted by selecting the count of rows in the  `2018_Yellow_Taxi_Trip_Data` where vendorID is 2.

Explain why the size of the base and database folders changed as a result of the delete statement.

4. Answer

Before deleting rows where vendorID is 2.

|folder_name  | size |
|--|--|
|base  |15.2 GB  |
|size_of_database  |13.1 GB  |

After deleting rows where vendorID is 2. Code can be found in corresponding SQL script.

|folder_name  | size |
|--|--|
|base  |15.2 GB  |
|size_of_database  |13.1 GB  |

I thought this was interesting. The amount of storage dedicated to PosqreSQL did not change after the delete. As a check, I ran the following code, and it returned 0.

`select count("VendorID") from taxi_data td where "VendorID" = 2;`

5. Exercise

Run the command below

    VACUUM FULL;

Inspect the size of the base and database folders. Can you explain what happened?

5. Answer

I looked up the PostgreSQL documentation for the `VACUUM` function which may be found [here](https://www.postgresql.org/docs/current/sql-vacuum.html). This code reclaims storage occupied by dead tuples. In the previous problem we queried a script to delete all rows where "VendorID" is 2. However, this does not mean that the space allocated by PostgreSQL in storage was freed up. This frees up that memory. Let's take another look at the size of the base and database folders.

|folder_name  | size |
|--|--|
|base  |7.65 GB  |
|size_of_database  |5.58 GB  |

The `VACUUM` function worked as expected!

6. Exercise

Truncate the table `2018_Yellow_Taxi_Trip_Data` and re-import the `2018_Yellow_Taxi_Trip_Data`.

6. Answer

The code to truncate the dataset can be found in the corresponding SQL script. I re-imported the dataset. See you in 6 hours!
